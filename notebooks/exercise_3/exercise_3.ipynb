{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67ca78c8-3726-4c51-be97-d5e4857f6aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nice to have and only here as a reference until moved to its instructional home :)\n",
    "#export CUDNN_PATH=$(dirname $(python -c \"import nvidia.cudnn; print(nvidia.cudnn.__file__)\"))\n",
    "#export SITE_PACKAGES_PATH=$(python -c \"import site; print(site.getsitepackages()[0])\")\n",
    "#export LD_LIBRARY_PATH=$CUDNN_PATH/lib:$SITE_PACKAGES_PATH/tensorrt_libs/:$LD_LIBRARY_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3392c75e-4daa-434b-9030-7e344c77a332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /home/flaniganp/mambaforge/envs/torch_exercise_3:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "_libgcc_mutex             0.1                 conda_forge    conda-forge\n",
      "_openmp_mutex             4.5                       2_gnu    conda-forge\n",
      "anyio                     4.3.0                    pypi_0    pypi\n",
      "argon2-cffi               23.1.0                   pypi_0    pypi\n",
      "argon2-cffi-bindings      21.2.0                   pypi_0    pypi\n",
      "arrow                     1.3.0                    pypi_0    pypi\n",
      "asttokens                 2.4.1                    pypi_0    pypi\n",
      "async-lru                 2.0.4                    pypi_0    pypi\n",
      "attrs                     23.2.0                   pypi_0    pypi\n",
      "babel                     2.14.0                   pypi_0    pypi\n",
      "beautifulsoup4            4.12.3                   pypi_0    pypi\n",
      "bleach                    6.1.0                    pypi_0    pypi\n",
      "bzip2                     1.0.8                hd590300_5    conda-forge\n",
      "ca-certificates           2024.2.2             hbcca054_0    conda-forge\n",
      "certifi                   2024.2.2                 pypi_0    pypi\n",
      "cffi                      1.16.0                   pypi_0    pypi\n",
      "charset-normalizer        3.3.2                    pypi_0    pypi\n",
      "comm                      0.2.1                    pypi_0    pypi\n",
      "contourpy                 1.2.0                    pypi_0    pypi\n",
      "cycler                    0.12.1                   pypi_0    pypi\n",
      "debugpy                   1.8.1                    pypi_0    pypi\n",
      "decorator                 5.1.1                    pypi_0    pypi\n",
      "defusedxml                0.7.1                    pypi_0    pypi\n",
      "exceptiongroup            1.2.0                    pypi_0    pypi\n",
      "executing                 2.0.1                    pypi_0    pypi\n",
      "fastjsonschema            2.19.1                   pypi_0    pypi\n",
      "filelock                  3.13.1                   pypi_0    pypi\n",
      "fonttools                 4.49.0                   pypi_0    pypi\n",
      "fqdn                      1.5.1                    pypi_0    pypi\n",
      "fsspec                    2024.2.0                 pypi_0    pypi\n",
      "h11                       0.14.0                   pypi_0    pypi\n",
      "httpcore                  1.0.4                    pypi_0    pypi\n",
      "httpx                     0.27.0                   pypi_0    pypi\n",
      "idna                      3.6                      pypi_0    pypi\n",
      "ipykernel                 6.29.3                   pypi_0    pypi\n",
      "ipython                   8.22.2                   pypi_0    pypi\n",
      "isoduration               20.11.0                  pypi_0    pypi\n",
      "jedi                      0.19.1                   pypi_0    pypi\n",
      "jinja2                    3.1.3                    pypi_0    pypi\n",
      "joblib                    1.3.2                    pypi_0    pypi\n",
      "json5                     0.9.20                   pypi_0    pypi\n",
      "jsonpointer               2.4                      pypi_0    pypi\n",
      "jsonschema                4.21.1                   pypi_0    pypi\n",
      "jsonschema-specifications 2023.12.1                pypi_0    pypi\n",
      "jupyter-client            8.6.0                    pypi_0    pypi\n",
      "jupyter-core              5.7.1                    pypi_0    pypi\n",
      "jupyter-events            0.9.0                    pypi_0    pypi\n",
      "jupyter-lsp               2.2.3                    pypi_0    pypi\n",
      "jupyter-server            2.13.0                   pypi_0    pypi\n",
      "jupyter-server-terminals  0.5.2                    pypi_0    pypi\n",
      "jupyterlab                4.1.3                    pypi_0    pypi\n",
      "jupyterlab-pygments       0.3.0                    pypi_0    pypi\n",
      "jupyterlab-server         2.25.3                   pypi_0    pypi\n",
      "kiwisolver                1.4.5                    pypi_0    pypi\n",
      "ld_impl_linux-64          2.40                 h41732ed_0    conda-forge\n",
      "libffi                    3.4.2                h7f98852_5    conda-forge\n",
      "libgcc-ng                 13.2.0               h807b86a_5    conda-forge\n",
      "libgomp                   13.2.0               h807b86a_5    conda-forge\n",
      "libnsl                    2.0.1                hd590300_0    conda-forge\n",
      "libsqlite                 3.45.1               h2797004_0    conda-forge\n",
      "libuuid                   2.38.1               h0b41bf4_0    conda-forge\n",
      "libxcrypt                 4.4.36               hd590300_1    conda-forge\n",
      "libzlib                   1.2.13               hd590300_5    conda-forge\n",
      "matplotlib                3.8.3                    pypi_0    pypi\n",
      "matplotlib-inline         0.1.6                    pypi_0    pypi\n",
      "mistune                   3.0.2                    pypi_0    pypi\n",
      "mpmath                    1.3.0                    pypi_0    pypi\n",
      "nbclient                  0.9.0                    pypi_0    pypi\n",
      "nbconvert                 7.16.2                   pypi_0    pypi\n",
      "nbformat                  5.9.2                    pypi_0    pypi\n",
      "ncurses                   6.4                  h59595ed_2    conda-forge\n",
      "nest-asyncio              1.6.0                    pypi_0    pypi\n",
      "networkx                  3.2.1                    pypi_0    pypi\n",
      "notebook                  7.1.1                    pypi_0    pypi\n",
      "notebook-shim             0.2.4                    pypi_0    pypi\n",
      "numpy                     1.26.4                   pypi_0    pypi\n",
      "nvidia-cublas-cu12        12.1.3.1                 pypi_0    pypi\n",
      "nvidia-cuda-cupti-cu12    12.1.105                 pypi_0    pypi\n",
      "nvidia-cuda-nvrtc-cu12    12.1.105                 pypi_0    pypi\n",
      "nvidia-cuda-runtime-cu12  12.1.105                 pypi_0    pypi\n",
      "nvidia-cudnn-cu12         8.9.2.26                 pypi_0    pypi\n",
      "nvidia-cufft-cu12         11.0.2.54                pypi_0    pypi\n",
      "nvidia-curand-cu12        10.3.2.106               pypi_0    pypi\n",
      "nvidia-cusolver-cu12      11.4.5.107               pypi_0    pypi\n",
      "nvidia-cusparse-cu12      12.1.0.106               pypi_0    pypi\n",
      "nvidia-nccl-cu12          2.19.3                   pypi_0    pypi\n",
      "nvidia-nvjitlink-cu12     12.3.101                 pypi_0    pypi\n",
      "nvidia-nvtx-cu12          12.1.105                 pypi_0    pypi\n",
      "openssl                   3.2.1                hd590300_0    conda-forge\n",
      "overrides                 7.7.0                    pypi_0    pypi\n",
      "pandocfilters             1.5.1                    pypi_0    pypi\n",
      "parso                     0.8.3                    pypi_0    pypi\n",
      "pexpect                   4.9.0                    pypi_0    pypi\n",
      "pillow                    10.2.0                   pypi_0    pypi\n",
      "pip                       24.0               pyhd8ed1ab_0    conda-forge\n",
      "platformdirs              4.2.0                    pypi_0    pypi\n",
      "prometheus-client         0.20.0                   pypi_0    pypi\n",
      "prompt-toolkit            3.0.43                   pypi_0    pypi\n",
      "psutil                    5.9.8                    pypi_0    pypi\n",
      "ptyprocess                0.7.0                    pypi_0    pypi\n",
      "pure-eval                 0.2.2                    pypi_0    pypi\n",
      "pycparser                 2.21                     pypi_0    pypi\n",
      "pygments                  2.17.2                   pypi_0    pypi\n",
      "pyparsing                 3.1.1                    pypi_0    pypi\n",
      "python                    3.10.13         hd12c33a_1_cpython    conda-forge\n",
      "python-dateutil           2.9.0.post0              pypi_0    pypi\n",
      "python-json-logger        2.0.7                    pypi_0    pypi\n",
      "pyyaml                    6.0.1                    pypi_0    pypi\n",
      "pyzmq                     25.1.2                   pypi_0    pypi\n",
      "readline                  8.2                  h8228510_1    conda-forge\n",
      "referencing               0.33.0                   pypi_0    pypi\n",
      "requests                  2.31.0                   pypi_0    pypi\n",
      "rfc3339-validator         0.1.4                    pypi_0    pypi\n",
      "rfc3986-validator         0.1.1                    pypi_0    pypi\n",
      "rpds-py                   0.18.0                   pypi_0    pypi\n",
      "scikit-learn              1.4.1.post1              pypi_0    pypi\n",
      "scipy                     1.12.0                   pypi_0    pypi\n",
      "send2trash                1.8.2                    pypi_0    pypi\n",
      "setuptools                69.1.1             pyhd8ed1ab_0    conda-forge\n",
      "six                       1.16.0                   pypi_0    pypi\n",
      "sniffio                   1.3.1                    pypi_0    pypi\n",
      "soupsieve                 2.5                      pypi_0    pypi\n",
      "stack-data                0.6.3                    pypi_0    pypi\n",
      "sympy                     1.12                     pypi_0    pypi\n",
      "terminado                 0.18.0                   pypi_0    pypi\n",
      "threadpoolctl             3.3.0                    pypi_0    pypi\n",
      "tinycss2                  1.2.1                    pypi_0    pypi\n",
      "tk                        8.6.13          noxft_h4845f30_101    conda-forge\n",
      "tomli                     2.0.1                    pypi_0    pypi\n",
      "torch                     2.2.1                    pypi_0    pypi\n",
      "torchvision               0.17.1                   pypi_0    pypi\n",
      "tornado                   6.4                      pypi_0    pypi\n",
      "traitlets                 5.14.1                   pypi_0    pypi\n",
      "triton                    2.2.0                    pypi_0    pypi\n",
      "types-python-dateutil     2.8.19.20240106          pypi_0    pypi\n",
      "typing-extensions         4.10.0                   pypi_0    pypi\n",
      "tzdata                    2024a                h0c530f3_0    conda-forge\n",
      "uri-template              1.3.0                    pypi_0    pypi\n",
      "urllib3                   2.2.1                    pypi_0    pypi\n",
      "wcwidth                   0.2.13                   pypi_0    pypi\n",
      "webcolors                 1.13                     pypi_0    pypi\n",
      "webencodings              0.5.1                    pypi_0    pypi\n",
      "websocket-client          1.7.0                    pypi_0    pypi\n",
      "wheel                     0.42.0             pyhd8ed1ab_0    conda-forge\n",
      "xz                        5.2.6                h166bdaf_0    conda-forge\n"
     ]
    }
   ],
   "source": [
    "!conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2baf955f-2e55-4769-aea5-f3e99356c371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'matplotlib.pyplot' is a collection of functions in the 'matplotlib' library that make matplotlib work like MATLAB.\n",
    "# Each pyplot function makes some change to a figure: e.g., creates a figure, creates a plotting area in a figure,\n",
    "# plots some lines in a plotting area, decorates the plot with labels, etc. 'plt' is a commonly used shorthand alias\n",
    "# for 'matplotlib.pyplot'. This allows you to access matplotlib's plotting functions with shorter syntax - for example,\n",
    "# you can type 'plt.plot()' instead of 'matplotlib.pyplot.plot()'. This import is essential for data visualization,\n",
    "# allowing you to create a wide variety of static, animated, and interactive plots and charts in Python.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# The os module in Python provides a way of using operating system dependent functionality. It allows you to interface\n",
    "# with the underlying operating system that Python is running on â€“ be it Windows, Mac or Linux. You can use the os module\n",
    "# to handle file and directory paths, create folders, list contents of a directory, manage environment variables, execute\n",
    "# shell commands, and more.\n",
    "import os\n",
    "\n",
    "# A standard Python module for generating random numbers.\n",
    "import random\n",
    "\n",
    "# The 'requests' library is the de facto standard for making HTTP requests in Python. It abstracts the complexities of\n",
    "# making requests behind a beautiful, simple API, so that you can focus on interacting with services and consuming data\n",
    "# in your application. It's used here for downloading the dataset from a given URL.\n",
    "import requests\n",
    "\n",
    "# Regular Expressions\n",
    "# 1. search: This function is used to perform a search for a pattern in a string and returns a match object if the\n",
    "# pattern is found, otherwise None. It's particularly useful for string pattern matching and extracting specific\n",
    "# segments from text.\n",
    "from re import search\n",
    "\n",
    "# This line imports the 'check_output' function from the 'subprocess' module in Python. The 'subprocess' module\n",
    "# allows you to spawn new processes, connect to their input/output/error pipes, and obtain their return codes. This\n",
    "# module is intended to replace older modules and functions like os.system and os.spawn*.\n",
    "# Key aspects of 'check_output':\n",
    "# 1. **Process Execution**: The 'check_output' function is used to run a command in the subprocess/external process and\n",
    "#    capture its output. This is especially useful for running system commands and capturing their output directly\n",
    "#    within a Python script.\n",
    "# 2. **Return Output**: It returns the output of the command, making it available to the Python environment. If the\n",
    "#    called command results in an error (non-zero exit status), it raises a CalledProcessError.\n",
    "# 3. **Use Cases**: Common use cases include executing a shell command, reading the output of a command, automating\n",
    "#    scripts that interact with the command line, and integrating external tools into a Python workflow.\n",
    "\n",
    "# Example Usage:\n",
    "# Suppose you want to capture the output of the 'ls' command in a Unix/Linux system. You can use 'check_output' like\n",
    "# this:\n",
    "# output = check_output(['ls', '-l'])\n",
    "from subprocess import check_output\n",
    "\n",
    "# Importing the PyTorch library, known as `torch`, a powerful and widely used open-source machine learning framework.\n",
    "# PyTorch provides tools and libraries for designing, training, and deploying deep learning models with ease. It's\n",
    "# particularly known for its flexibility, user-friendly interface, and dynamic computational graph that allows for\n",
    "# adaptive and efficient deep learning development. By importing `torch`, you gain access to a vast range of\n",
    "# functionalities for handling multi-dimensional arrays (tensors), performing complex mathematical operations,\n",
    "# and utilizing GPUs for accelerated computing. This makes it an indispensable tool for both researchers and\n",
    "# developers in the field of artificial intelligence.\n",
    "import torch\n",
    "\n",
    "# nn from torch: Provides the building blocks for creating neural networks, including layers, activation functions,\n",
    "# and loss functions. It's a foundational module for defining and assembling neural network architectures.\n",
    "import torch.nn as nn\n",
    "\n",
    "# nn.functional from torch: Contains functions like activation functions, loss functions, and convolution operations.\n",
    "# These functions are stateless, providing a functional interface to operations that can be applied to tensors.\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# optim from torch: Implements various optimization algorithms for training neural networks, including SGD, Adam,\n",
    "# and RMSprop. These algorithms are used to update the weights of the network during training.\n",
    "import torch.optim as optim\n",
    "\n",
    "# Imports the quantize_dynamic function from PyTorch's quantization submodule. This function is used for dynamically \n",
    "# quantizing the weights of specified layers (e.g., Linear, LSTM) in a trained PyTorch model to int8 format, reducing\n",
    "# model size and potentially increasing inference speed without needing input data for calibration.\n",
    "from torch.quantization import quantize_dynamic\n",
    "\n",
    "# A toolbox for computer vision tasks in Python. It includes:\n",
    "# 1. 'datasets' for accessing a variety of pre-prepared image collections for training models.\n",
    "# 2. 'transforms' for editing and adjusting images (like resizing or color changes) to improve model learning.\n",
    "import torchvision\n",
    "\n",
    "# This imports the DataLoader class from PyTorch's utility functions. DataLoader is essential for loading the data and\n",
    "# feeding it into the network in batches. It offers the ability to shuffle the data, load it in parallel using\n",
    "# multiprocessing, and more, thus providing an efficient way to iterate over data.\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# The 'zipfile' module in Python is used for reading and writing ZIP files. It allows you to create, read, write,\n",
    "# append, and list ZIP files. In this context, it's used to extract the downloaded dataset, which is assumed to be in a\n",
    "# ZIP format, into a designated directory for further processing and use in the training process.\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37c87e2d-cb55-42da-bc40-0a0338bb06cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function `print_gpu_info` is designed to display detailed information about the available GPUs on the system.\n",
    "# It utilizes TensorFlow's `device_lib.list_local_devices()` method to enumerate all computing devices recognized by\n",
    "# TensorFlow. For each device identified as a GPU, the function extracts and prints relevant details including the GPU's\n",
    "# ID, name, memory limit (converted to megabytes), and compute capability. The extraction of GPU information involves\n",
    "# parsing the device's description string using regular expressions to find specific pieces of information. This\n",
    "# function can be particularly useful for debugging or for setting up configurations in environments with multiple GPUs,\n",
    "# ensuring that TensorFlow is utilizing the GPUs as expected.\n",
    "\n",
    "def print_gpu_info():\n",
    "    # Undocumented Method\n",
    "    # https://stackoverflow.com/questions/38559755/how-to-get-current-available-gpus-in-tensorflow\n",
    "    # Get the list of all devices\n",
    "    devices = device_lib.list_local_devices()\n",
    "\n",
    "    for device in devices:\n",
    "        if device.device_type == 'GPU':\n",
    "            # Extract the physical device description\n",
    "            desc = device.physical_device_desc\n",
    "\n",
    "            # Use regular expressions to extract the required information\n",
    "            gpu_id_match = search(r'device: (\\d+)', desc)\n",
    "            name_match = search(r'name: (.*?),', desc)\n",
    "            compute_capability_match = search(r'compute capability: (\\d+\\.\\d+)', desc)\n",
    "\n",
    "            if gpu_id_match and name_match and compute_capability_match:\n",
    "                gpu_id = gpu_id_match.group(1)\n",
    "                gpu_name = name_match.group(1)\n",
    "                compute_capability = compute_capability_match.group(1)\n",
    "\n",
    "                # Convert memory limit from bytes to gigabytes and round it\n",
    "                memory_limit_gb = round(device.memory_limit / (1024 ** 2))\n",
    "\n",
    "                print(\n",
    "                    f\"\\tGPU ID {gpu_id} --> {gpu_name} --> \"\n",
    "                    f\"Memory Limit {memory_limit_gb} MB --> \"\n",
    "                    f\"Compute Capability {compute_capability}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2124786-67b1-4515-a40e-09b3a1b99895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA Driver: 545.23.08\n",
      "Maximum Supported CUDA Version: 12.3     \n"
     ]
    }
   ],
   "source": [
    "# NVIDIA Driver\n",
    "try:\n",
    "    # Execute the nvidia-smi command and decode the output\n",
    "    nvidia_smi_output = check_output(\"nvidia-smi\", shell=True).decode()\n",
    "\n",
    "    # Split the output into lines\n",
    "    lines = nvidia_smi_output.split('\\n')\n",
    "\n",
    "    # Find the line containing the driver version\n",
    "    driver_line = next((line for line in lines if \"Driver Version\" in line), None)\n",
    "\n",
    "    # Extract the driver version number\n",
    "    if driver_line:\n",
    "        driver_version = driver_line.split('Driver Version: ')[1].split()[0]\n",
    "        print(\"NVIDIA Driver:\", driver_version)\n",
    "\n",
    "        # Extract the maximum supported CUDA version\n",
    "        cuda_version = driver_line.split('CUDA Version: ')[1].strip().replace(\"|\", \"\")\n",
    "        print(\"Maximum Supported CUDA Version:\", cuda_version)\n",
    "    else:\n",
    "        print(\"NVIDIA Driver Version or CUDA Version not found.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error fetching NVIDIA Driver Version or CUDA Version:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "431b2e44-2f7e-4915-be8e-4c06e981acef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Software Versions:\n",
      "CUDA Version 11.8.89\n"
     ]
    }
   ],
   "source": [
    "print(\"Software Versions:\")\n",
    "\n",
    "# CUDA\n",
    "try:\n",
    "    # Execute the 'nvcc --version' command and decode the output\n",
    "    nvcc_output = check_output(\"nvcc --version\", shell=True).decode()\n",
    "\n",
    "    # Use regular expression to find the version number\n",
    "    match = search(r\"V(\\d+\\.\\d+\\.\\d+)\", nvcc_output)\n",
    "    if match:\n",
    "        cuda_version = match.group(1)\n",
    "        print(\"CUDA Version\", cuda_version)\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        print(\"CUDA Version not found\")\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "except CalledProcessError as e:\n",
    "    print(\"Error executing nvcc --version:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be62d333-e731-42ac-88cd-ef06379a7963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECTION 1: MODEL DEFINITION\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "# This section defines the TrafficSignNet neural network architecture for traffic sign classification. The network\n",
    "# consists of:\n",
    "# - Two convolutional layers for feature extraction, with ReLU activations and max pooling for non-linearity and spatial\n",
    "# reduction.\n",
    "# - Two fully connected (dense) layers for classification, translating the high-dimensional feature representations into\n",
    "# class predictions.\n",
    "# - The forward pass method outlines the data flow through the network, applying each layer sequentially to produce the\n",
    "# final output.\n",
    "# This architecture is designed to work with RGB images and assumes a specific input size, with the output layer sized\n",
    "# to match the number of traffic sign classes.\n",
    "\n",
    "class TrafficSignNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TrafficSignNet, self).__init__()\n",
    "        # Define the first convolutional layer: 3 input channels for RGB images, 32 output channels, 3x3 kernels,\n",
    "        # padding to maintain size\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "\n",
    "        # Define the second convolutional layer: Increase depth to 64 feature maps, 3x3 kernels, padding to maintain\n",
    "        # size\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        # Define the first fully connected layer: Flatten feature maps to vector, connect to 128 neurons\n",
    "        # Adjust input size based on the size of feature maps after conv and pooling layers\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)  # Assumes [64, 7, 7] feature maps size before flattening\n",
    "\n",
    "        # Define the second fully connected layer: Map 128-dimensional vector to the number of classes (e.g., 43 for\n",
    "        # traffic signs)\n",
    "        self.fc2 = nn.Linear(128, 43)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply first conv layer, ReLU activation, and 2x2 max pooling, reducing spatial dimensions\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "\n",
    "        # Apply second conv layer, ReLU activation, and 2x2 max pooling, further reducing spatial dimensions\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "\n",
    "        # Flatten the feature maps into a vector for the dense layers\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "\n",
    "        # Apply the first dense layer with ReLU activation to introduce non-linearity\n",
    "        x = F.relu(self.fc1(x))\n",
    "\n",
    "        # Apply the second dense layer to produce class scores/logits\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # Apply log softmax to convert logits to log probabilities for each class\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34a249a2-6c75-4c0e-9777-ea891ad6585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECTION 2: TRAINING FUNCTION\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "# This section defines the `train_model` function, responsible for training the neural network model for one epoch. The\n",
    "# process includes:\n",
    "# - Setting the model to training mode to enable certain layers like Dropout and BatchNorm to behave accordingly.\n",
    "# - Iterating over batches of training data, moving them to the appropriate device (GPU/CPU).\n",
    "# - Performing a forward pass to compute predictions, followed by calculating the loss using the true labels.\n",
    "# - Conducting a backward pass to compute gradients of the loss with respect to the model parameters.\n",
    "# - Updating model parameters with an optimization step to minimize the loss.\n",
    "# - Periodically printing training statistics to monitor the progress. This function encapsulates the core training\n",
    "# loop, crucial for model optimization.\n",
    "\n",
    "def train_model(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()  # Switch model to training mode to activate layers like Dropout and BatchNorm correctly\n",
    "\n",
    "    # Calculate the total number of batches in the train_loader to determine progress intervals.\n",
    "    total_batches = len(train_loader)\n",
    "    # Calculate what constitutes 10% of total batches for progress updates.\n",
    "    ten_percent_batches = total_batches / 10\n",
    "    # Create a list of batch indices where each represents a 10% progress milestone.\n",
    "    milestones = [int(ten_percent_batches * i) for i in range(1, 11)]\n",
    "    \n",
    "    # Loop through each batch from the training data loader\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)  # Transfer data and targets to the specified device (GPU/CPU)\n",
    "\n",
    "        optimizer.zero_grad()  # Clear previous gradients, if any, to prevent accumulation\n",
    "\n",
    "        # Forward pass: Calculate model's predictions for the current batch of data\n",
    "        output = model(data)\n",
    "\n",
    "        # Calculate the loss by comparing the model's predictions with the actual labels\n",
    "        loss = F.nll_loss(output, target)\n",
    "\n",
    "        # Backward pass: Compute gradients of all model parameters with respect to the loss\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters based on gradients computed during the backward pass\n",
    "        optimizer.step()\n",
    "\n",
    "        # Check if the current batch index matches any of the predefined milestones for 10% increments.\n",
    "        if batch_idx in milestones:\n",
    "            # Print the training progress, including epoch, number of samples processed, total number of samples,\n",
    "            # percentage of progress, and the current loss value.\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e278497d-9542-4df5-9184-2fcd80f402d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECTION 3: DATASET CREATION\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "# This section outlines the dataset preparation and transformation process, crucial for training and evaluating the\n",
    "# neural network model:\n",
    "# - The `download_and_extract_data` function is responsible for downloading the dataset from a specified URL and\n",
    "# extracting it into a local directory, setting up the data for further processing.\n",
    "# - A `preprocess` function is defined to apply a series of transformations to the input images, making them suitable\n",
    "# for model processing. This includes resizing images to a uniform size, converting them to PyTorch tensors, and\n",
    "# normalizing their pixel values.\n",
    "# - The `create_datasets` function loads the training and validation (or test) datasets from specified directories,\n",
    "# applying the preprocessing transformations.\n",
    "# - The `create_data_loaders` function wraps the datasets in PyTorch DataLoader instances, facilitating efficient batch\n",
    "# processing, data shuffling for the training set, and parallel data loading.\n",
    "\n",
    "# Function to download and extract the dataset\n",
    "def download_and_extract_data(url, data_path='data'):\n",
    "    if not os.path.exists(data_path):\n",
    "        os.makedirs(data_path)  # Create the data directory if it doesn't exist\n",
    "\n",
    "    zip_path = os.path.join(data_path, 'dataset.zip')  # Define the full path for the zip file\n",
    "\n",
    "    # Download the zip file from the provided URL\n",
    "    response = requests.get(url)\n",
    "    with open(zip_path, 'wb') as f:\n",
    "        f.write(response.content)  # Write the content to the zip file\n",
    "\n",
    "    # Extract the contents of the zip file\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(data_path)  # Extract all the files into the data directory\n",
    "\n",
    "    os.remove(zip_path)  # Remove the zip file to free up space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "427588cb-1bec-46ba-a711-85a976a0a532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess function adapted for PyTorch\n",
    "def preprocess(img_shape=30):\n",
    "    return torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((img_shape, img_shape)),  # Resize images to a consistent size\n",
    "        torchvision.transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "        torchvision.transforms.Normalize((0.5,), (0.5,))  # Normalize the tensors\n",
    "    ])\n",
    "\n",
    "\n",
    "def create_datasets(data_path, transform):\n",
    "    # Load images from the training directory and apply preprocessing transformations\n",
    "    train_dataset = torchvision.datasets.ImageFolder(root=os.path.join(data_path, 'train'), transform=transform)\n",
    "\n",
    "    # Load images from the validation directory and apply the same transformations\n",
    "    test_dataset = torchvision.datasets.ImageFolder(root=os.path.join(data_path, 'validation'), transform=transform)\n",
    "\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "\n",
    "def create_data_loaders(train_dataset, test_dataset, batch_size=32):\n",
    "    # DataLoader for the training dataset\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "    # DataLoader for the test dataset\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2e3d71c-18fa-4a61-b31f-54b72e6760ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECTION 4: DATASET CREATION\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "# This section is dedicated to the testing and evaluation of the trained neural network model:\n",
    "# - The `evaluate_model` function computes the model's performance metrics, such as accuracy, on the test dataset.\n",
    "# This function iterates over the test dataset, computes the model's predictions, and compares them with the true labels\n",
    "# to calculate accuracy or other relevant metrics.\n",
    "# - Optionally, this section can include functions for visualizing predictions, confusion matrices, or other analysis\n",
    "# tools that provide insights into the model's performance and behavior.\n",
    "def evaluate_model(model, device, test_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # Sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max log-probability as the prediction\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "    print(f'Test set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
    "          f'({accuracy:.0f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6c43656-1a4f-4275-826f-a5d22fa875b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Function to visualize test results or model predictions\n",
    "def visualize_predictions(model, device, test_loader, num_images=5):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # Randomly sample 'num_images' indices from the test dataset\n",
    "    indices = random.sample(range(len(test_loader.dataset)), num_images)\n",
    "\n",
    "    # Initialize lists to store sampled images and labels\n",
    "    sampled_images = []\n",
    "    sampled_labels = []\n",
    "\n",
    "    # Obtain the images and labels for the randomly sampled indices\n",
    "    for idx in indices:\n",
    "        image, label = test_loader.dataset[idx]\n",
    "        sampled_images.append(image)\n",
    "        sampled_labels.append(label)\n",
    "\n",
    "    # Stack the list of images into a batch and transfer to the device\n",
    "    image_batch = torch.stack(sampled_images).to(device)\n",
    "\n",
    "    # Generate predictions from the model by passing the batch of images through it\n",
    "    output = model(image_batch)\n",
    "    _, preds = torch.max(output, 1)\n",
    "\n",
    "    # Create a new figure with specified width and height\n",
    "    plt.figure(figsize=(15, 3))\n",
    "\n",
    "    # Display each sampled image with its prediction and actual label\n",
    "    for idx in range(num_images):\n",
    "        ax = plt.subplot(1, num_images, idx + 1)\n",
    "        img = sampled_images[idx].numpy().transpose(1, 2, 0)\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f'Predicted: {preds[idx].item()}\\nActual: {sampled_labels[idx]}')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65dce7d5-3c1f-4ca1-bfde-ca8b3f5d3320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [3136/31367 (10%)]\tLoss: 2.508795\n",
      "Train Epoch: 1 [6272/31367 (20%)]\tLoss: 1.362379\n",
      "Train Epoch: 1 [9408/31367 (30%)]\tLoss: 1.089339\n",
      "Train Epoch: 1 [12544/31367 (40%)]\tLoss: 0.605781\n",
      "Train Epoch: 1 [15680/31367 (50%)]\tLoss: 0.444296\n",
      "Train Epoch: 1 [18816/31367 (60%)]\tLoss: 0.405483\n",
      "Train Epoch: 1 [21952/31367 (70%)]\tLoss: 0.434043\n",
      "Train Epoch: 1 [25088/31367 (80%)]\tLoss: 0.340337\n",
      "Train Epoch: 1 [28224/31367 (90%)]\tLoss: 0.691154\n",
      "Train Epoch: 2 [3136/31367 (10%)]\tLoss: 0.267625\n",
      "Train Epoch: 2 [6272/31367 (20%)]\tLoss: 0.330753\n",
      "Train Epoch: 2 [9408/31367 (30%)]\tLoss: 0.124108\n",
      "Train Epoch: 2 [12544/31367 (40%)]\tLoss: 0.440904\n",
      "Train Epoch: 2 [15680/31367 (50%)]\tLoss: 0.381760\n",
      "Train Epoch: 2 [18816/31367 (60%)]\tLoss: 0.245789\n",
      "Train Epoch: 2 [21952/31367 (70%)]\tLoss: 0.091512\n",
      "Train Epoch: 2 [25088/31367 (80%)]\tLoss: 0.116425\n",
      "Train Epoch: 2 [28224/31367 (90%)]\tLoss: 0.086806\n",
      "Train Epoch: 3 [3136/31367 (10%)]\tLoss: 0.059095\n",
      "Train Epoch: 3 [6272/31367 (20%)]\tLoss: 0.020297\n",
      "Train Epoch: 3 [9408/31367 (30%)]\tLoss: 0.025791\n",
      "Train Epoch: 3 [12544/31367 (40%)]\tLoss: 0.153906\n",
      "Train Epoch: 3 [15680/31367 (50%)]\tLoss: 0.056546\n",
      "Train Epoch: 3 [18816/31367 (60%)]\tLoss: 0.029111\n",
      "Train Epoch: 3 [21952/31367 (70%)]\tLoss: 0.007236\n",
      "Train Epoch: 3 [25088/31367 (80%)]\tLoss: 0.252936\n",
      "Train Epoch: 3 [28224/31367 (90%)]\tLoss: 0.010994\n",
      "Train Epoch: 4 [3136/31367 (10%)]\tLoss: 0.026399\n",
      "Train Epoch: 4 [6272/31367 (20%)]\tLoss: 0.059763\n",
      "Train Epoch: 4 [9408/31367 (30%)]\tLoss: 0.021106\n",
      "Train Epoch: 4 [12544/31367 (40%)]\tLoss: 0.011112\n",
      "Train Epoch: 4 [15680/31367 (50%)]\tLoss: 0.093502\n",
      "Train Epoch: 4 [18816/31367 (60%)]\tLoss: 0.041288\n",
      "Train Epoch: 4 [21952/31367 (70%)]\tLoss: 0.128428\n",
      "Train Epoch: 4 [25088/31367 (80%)]\tLoss: 0.139103\n",
      "Train Epoch: 4 [28224/31367 (90%)]\tLoss: 0.069175\n",
      "Train Epoch: 5 [3136/31367 (10%)]\tLoss: 0.093707\n",
      "Train Epoch: 5 [6272/31367 (20%)]\tLoss: 0.028844\n",
      "Train Epoch: 5 [9408/31367 (30%)]\tLoss: 0.004831\n",
      "Train Epoch: 5 [12544/31367 (40%)]\tLoss: 0.073074\n",
      "Train Epoch: 5 [15680/31367 (50%)]\tLoss: 0.021593\n",
      "Train Epoch: 5 [18816/31367 (60%)]\tLoss: 0.001524\n",
      "Train Epoch: 5 [21952/31367 (70%)]\tLoss: 0.022101\n",
      "Train Epoch: 5 [25088/31367 (80%)]\tLoss: 0.009653\n",
      "Train Epoch: 5 [28224/31367 (90%)]\tLoss: 0.077886\n",
      "Train Epoch: 6 [3136/31367 (10%)]\tLoss: 0.028058\n",
      "Train Epoch: 6 [6272/31367 (20%)]\tLoss: 0.009485\n",
      "Train Epoch: 6 [9408/31367 (30%)]\tLoss: 0.003656\n",
      "Train Epoch: 6 [12544/31367 (40%)]\tLoss: 0.045149\n",
      "Train Epoch: 6 [15680/31367 (50%)]\tLoss: 0.006908\n",
      "Train Epoch: 6 [18816/31367 (60%)]\tLoss: 0.087623\n",
      "Train Epoch: 6 [21952/31367 (70%)]\tLoss: 0.061470\n",
      "Train Epoch: 6 [25088/31367 (80%)]\tLoss: 0.088991\n",
      "Train Epoch: 6 [28224/31367 (90%)]\tLoss: 0.017268\n",
      "Train Epoch: 7 [3136/31367 (10%)]\tLoss: 0.104188\n",
      "Train Epoch: 7 [6272/31367 (20%)]\tLoss: 0.021882\n",
      "Train Epoch: 7 [9408/31367 (30%)]\tLoss: 0.008397\n",
      "Train Epoch: 7 [12544/31367 (40%)]\tLoss: 0.102553\n",
      "Train Epoch: 7 [15680/31367 (50%)]\tLoss: 0.054964\n",
      "Train Epoch: 7 [18816/31367 (60%)]\tLoss: 0.070026\n",
      "Train Epoch: 7 [21952/31367 (70%)]\tLoss: 0.003435\n",
      "Train Epoch: 7 [25088/31367 (80%)]\tLoss: 0.004682\n",
      "Train Epoch: 7 [28224/31367 (90%)]\tLoss: 0.011238\n",
      "Train Epoch: 8 [3136/31367 (10%)]\tLoss: 0.003378\n",
      "Train Epoch: 8 [6272/31367 (20%)]\tLoss: 0.001619\n",
      "Train Epoch: 8 [9408/31367 (30%)]\tLoss: 0.004430\n",
      "Train Epoch: 8 [12544/31367 (40%)]\tLoss: 0.012972\n",
      "Train Epoch: 8 [15680/31367 (50%)]\tLoss: 0.002702\n",
      "Train Epoch: 8 [18816/31367 (60%)]\tLoss: 0.006576\n",
      "Train Epoch: 8 [21952/31367 (70%)]\tLoss: 0.006891\n",
      "Train Epoch: 8 [25088/31367 (80%)]\tLoss: 0.003835\n",
      "Train Epoch: 8 [28224/31367 (90%)]\tLoss: 0.057976\n",
      "Train Epoch: 9 [3136/31367 (10%)]\tLoss: 0.002824\n",
      "Train Epoch: 9 [6272/31367 (20%)]\tLoss: 0.001632\n",
      "Train Epoch: 9 [9408/31367 (30%)]\tLoss: 0.001985\n",
      "Train Epoch: 9 [12544/31367 (40%)]\tLoss: 0.001030\n",
      "Train Epoch: 9 [15680/31367 (50%)]\tLoss: 0.001468\n",
      "Train Epoch: 9 [18816/31367 (60%)]\tLoss: 0.043390\n",
      "Train Epoch: 9 [21952/31367 (70%)]\tLoss: 0.025812\n",
      "Train Epoch: 9 [25088/31367 (80%)]\tLoss: 0.006956\n",
      "Train Epoch: 9 [28224/31367 (90%)]\tLoss: 0.000615\n",
      "Train Epoch: 10 [3136/31367 (10%)]\tLoss: 0.015735\n",
      "Train Epoch: 10 [6272/31367 (20%)]\tLoss: 0.001111\n",
      "Train Epoch: 10 [9408/31367 (30%)]\tLoss: 0.045327\n",
      "Train Epoch: 10 [12544/31367 (40%)]\tLoss: 0.008643\n",
      "Train Epoch: 10 [15680/31367 (50%)]\tLoss: 0.000247\n",
      "Train Epoch: 10 [18816/31367 (60%)]\tLoss: 0.000744\n",
      "Train Epoch: 10 [21952/31367 (70%)]\tLoss: 0.000126\n",
      "Train Epoch: 10 [25088/31367 (80%)]\tLoss: 0.007986\n",
      "Train Epoch: 10 [28224/31367 (90%)]\tLoss: 0.064465\n"
     ]
    }
   ],
   "source": [
    "# URL for the dataset to be downloaded\n",
    "url = 'https://storage.googleapis.com/download.tensorflow.org/data/certificate/germantrafficsigns.zip'\n",
    "data_path = 'data'  # Local directory where the dataset will be stored\n",
    "\n",
    "# Download and extract the dataset\n",
    "download_and_extract_data(url, data_path)\n",
    "\n",
    "# Define the image transformations\n",
    "transform = preprocess()\n",
    "\n",
    "# Create the datasets\n",
    "train_dataset, test_dataset = create_datasets(data_path, transform)\n",
    "\n",
    "# Create the data loaders\n",
    "train_loader, test_loader = create_data_loaders(train_dataset, test_dataset)\n",
    "\n",
    "# Initialize the model and transfer it to the computation device\n",
    "model = TrafficSignNet().to(device)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 10\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_model(model, device, train_loader, optimizer, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5483189-c156-4567-aecd-55641bc3f852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the class names directly from the dataset's 'classes' attribute.\n",
    "class_names = train_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ca8aba1-8dc9-4e80-9bfd-2ba7f6fbfcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model paths\n",
    "model_path = \"../../models/exercise_3_model.pth\"\n",
    "quantized_model_path = \"../../models/quantized_exercise_3_model.pth\"\n",
    "best_model_path = \"../../models/exercise_3/best.pth\"\n",
    "\n",
    "# Extract the directory paths\n",
    "model_dir = os.path.dirname(model_path)\n",
    "best_model_dir = os.path.dirname(best_model_path)\n",
    "\n",
    "# Create the directories if they do not exist\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "os.makedirs(best_model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d004fdf9-1df0-46fd-93c9-adbf4fbca4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.0668, Accuracy: 7728/7842 (99%)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "evaluate_model(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89cc5e9d-eaa9-406b-a786-d1df13244fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the final trained model's state dictionary to a file named '../models/exercise_1_model.pth'. This file can\n",
    "# be used later for further use or deployment.\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f28381a7-dec4-42a1-8cb5-3de54cf34fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 1709228 bytes, or 1.63 MB\n"
     ]
    }
   ],
   "source": [
    "# Get the size of the model\n",
    "model_size = os.path.getsize(model_path)\n",
    "\n",
    "# Convert size to more readable format (e.g., in MB)\n",
    "model_size_mb = model_size / (1024 * 1024)\n",
    "\n",
    "print(f\"Model size: {model_size} bytes, or {model_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47caec1d-c7f3-4019-9787-3274bb0f28b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize some test results\n",
    "visualize_predictions(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a417b97-b7c4-4335-a240-b5f17d15cccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'model' is your pre-trained FashionMNIST model\n",
    "model.eval()  # Ensure the model is in evaluation mode\n",
    "\n",
    "# Move your model to CPU (quantization is typically done for CPU inference)\n",
    "model.to('cpu')\n",
    "\n",
    "# Apply dynamic quantization\n",
    "# Note: Changing dtype to torch.qint8 for quantization, which is a common practice\n",
    "quantized_model = quantize_dynamic(\n",
    "    model, \n",
    "    {torch.nn.Linear},  # Specify the layer types to quantize\n",
    "    dtype=torch.qint8  # Use qint8 for quantizing the weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad5d9f2f-b71e-45a0-bc11-89b4d742a238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.0670, Accuracy: 7726/7842 (99%)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "evaluate_model(quantized_model, 'cpu', test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbfad68b-ae30-4948-990e-4e448277647b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the final trained model's state dictionary. This file can be used later for further use or deployment.\n",
    "torch.save(quantized_model.state_dict(), quantized_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b25f0a6e-2a7d-49c4-a3e7-3723835480ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized Model size: 490018 bytes, or 0.47 MB\n"
     ]
    }
   ],
   "source": [
    "# Get the size of the model\n",
    "model_size = os.path.getsize(quantized_model_path)\n",
    "\n",
    "# Convert size to more readable format (e.g., in MB)\n",
    "model_size_mb = model_size / (1024 * 1024)\n",
    "\n",
    "print(f\"Quantized Model size: {model_size} bytes, or {model_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ba4b4e8-201e-4134-9e05-9c3e9f152061",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize some test results\n",
    "visualize_predictions(model, 'cpu', test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
